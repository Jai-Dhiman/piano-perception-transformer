# My Piano Performance Analysis

**Personal recreation of PercePiano dataset analysis for deep learning fundamentals**

## Project Goal

Build piano performance analysis system from scratch to predict 19 perceptual dimensions:

- Timing, Articulation, Pedal, Timbre, Dynamics, Musical Expression, Emotion, Interpretation

## Approach

**Phase 1**: Dataset Recreation & ML Fundamentals (Current)

- âœ… Dataset exploration and correlation analysis
- âœ… Audio preprocessing pipeline
- ðŸš§ Feature extraction matching research approaches
- ðŸŽ¯ Single-dimension prediction model (next)

**Future Phases**: CNN architecture â†’ Multi-task learning â†’ Chopin/Liszt extension

## Repository Structure

```
my_implementation/
â”œâ”€â”€ src/           # Clean implementation code
â”œâ”€â”€ data/          # PercePiano labels and sample audio
â”œâ”€â”€ notebooks/     # Jupyter experiments 
â”œâ”€â”€ models/        # Trained model files
â”œâ”€â”€ experiments/   # Training configurations
â””â”€â”€ results/       # Analysis outputs
```

## Quick Start

```bash
cd src/
python dataset_analysis.py      # Analyze PercePiano dataset
python audio_preprocessing.py   # Test audio feature extraction
```

## Key Insights from Dataset Analysis

- **1202 performances** across 19 perceptual dimensions
- **22 performers**, multi-composer dataset (Schubert, Beethoven)  
- **Rating range**: [0.143, 0.976], mean=0.553
- **Strong correlations**: Related dimensions (pedal types, musical expression)
- **Audio features**: Tempoâ†’timing, spectral centroidâ†’brightness, RMSâ†’dynamics

## Next Steps

1. Build single-dimension prediction model (starting with "Timing_Stable_Unstable")
2. Implement multi-task learning for all 19 dimensions
3. Compare CNN vs traditional ML approaches
4. Extend to new repertoire (Chopin/Liszt recordings)

---
*Learning-focused implementation - building everything from scratch for deep understanding*
