{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Piano Perception Transformer - MAESTRO Training Pipeline\n",
    "\n",
    "This notebook implements the complete training pipeline:\n",
    "1. **SSAST Pre-training** on MAESTRO dataset\n",
    "2. **AST Fine-tuning** on PercePiano dataset\n",
    "\n",
    "**Runtime Requirements:**\n",
    "- Use **TPU v2-8**\n",
    "\n",
    "**Memory-Efficient Approach:**\n",
    "- Streaming MAESTRO processing (avoids 200GB storage limit)\n",
    "- Only keeps processed spectrograms (~10GB vs 200GB raw audio)\n",
    "- Automatic cleanup of raw audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Initial Setup\n",
    "print(\"üöÄ Setting up Piano Perception Transformer...\")\n",
    "\n",
    "# Clone repo (skip if already exists)\n",
    "import os\n",
    "if not os.path.exists('piano-perception-transformer'):\n",
    "    !git clone https://github.com/Jai-Dhiman/piano-perception-transformer.git\n",
    "else:\n",
    "    print(\"Repository already exists, skipping clone...\")\n",
    "\n",
    "%cd piano-perception-transformer\n",
    "\n",
    "# Install uv\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Fix the path and install dependencies\n",
    "print(\"üì¶ Installing dependencies with uv...\")\n",
    "!export PATH=\"/usr/local/bin:$PATH\" && uv pip install --system jax[tpu] flax optax librosa pandas wandb requests zipfile36\n",
    "\n",
    "print(\"‚úÖ Setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaggle_setup"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Mount Google Drive & Setup Memory-Efficient Storage\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"üíæ Mounting Google Drive for persistent storage...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for saving processed data and checkpoints\n",
    "!mkdir -p /content/drive/MyDrive/piano_transformer\n",
    "!mkdir -p /content/drive/MyDrive/piano_transformer/processed_spectrograms\n",
    "!mkdir -p /content/drive/MyDrive/piano_transformer/checkpoints\n",
    "!mkdir -p /content/drive/MyDrive/piano_transformer/logs\n",
    "!mkdir -p /content/drive/MyDrive/piano_transformer/temp\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted and directories created!\")\n",
    "print(\"üìÅ Storage structure:\")\n",
    "!ls -la /content/drive/MyDrive/piano_transformer/\n",
    "\n",
    "# Check available space\n",
    "!df -h /content\n",
    "print(\"‚úÖ Storage setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_maestro"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Streaming MAESTRO Processing\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from io import BytesIO\n",
    "sys.path.append('./src')\n",
    "\n",
    "print(\"üåä Starting streaming MAESTRO processing...\")\n",
    "\n",
    "def ensure_directories():\n",
    "    \"\"\"Create all necessary directories in Google Drive\"\"\"\n",
    "    directories = [\n",
    "        '/content/drive/MyDrive/piano_transformer',\n",
    "        '/content/drive/MyDrive/piano_transformer/processed_spectrograms',\n",
    "        '/content/drive/MyDrive/piano_transformer/checkpoints',\n",
    "        '/content/drive/MyDrive/piano_transformer/logs',\n",
    "        '/content/drive/MyDrive/piano_transformer/temp'\n",
    "    ]\n",
    "    \n",
    "    print(\"üìÅ Ensuring directory structure...\")\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"‚úÖ Created/verified: {directory}\")\n",
    "\n",
    "def download_and_process_maestro_streaming(max_files=None):\n",
    "    \"\"\"Download MAESTRO ZIP as stream, extract and process audio‚Üíspectrograms, save to Drive\"\"\"\n",
    "    \n",
    "    # Ensure directories exist first\n",
    "    ensure_directories()\n",
    "    \n",
    "    # Download metadata first to get real file paths\n",
    "    print(\"üìã Downloading MAESTRO metadata...\")\n",
    "    metadata_url = \"https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0.json\"\n",
    "    \n",
    "    try:\n",
    "        metadata_response = requests.get(metadata_url, timeout=30)\n",
    "        metadata_response.raise_for_status()\n",
    "        maestro_metadata = metadata_response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Failed to download metadata: {e}\")\n",
    "        raise Exception(f\"Cannot download MAESTRO metadata: {e}\")\n",
    "    \n",
    "    print(f\"üìä Found metadata for MAESTRO dataset\")\n",
    "    \n",
    "    # Save metadata to Drive\n",
    "    try:\n",
    "        with open('/content/drive/MyDrive/piano_transformer/maestro_metadata.json', 'w') as f:\n",
    "            json.dump(maestro_metadata, f)\n",
    "        print(\"‚úÖ Metadata saved to Drive\")\n",
    "    except IOError as e:\n",
    "        print(f\"‚ùå Failed to save metadata: {e}\")\n",
    "        raise Exception(f\"Cannot save metadata to Drive: {e}\")\n",
    "    \n",
    "    # MAESTRO v3.0.0 uses pandas-style JSON structure\n",
    "    if not isinstance(maestro_metadata, dict):\n",
    "        raise Exception(f\"Expected dict metadata, got {type(maestro_metadata)}\")\n",
    "    \n",
    "    # Check for required fields\n",
    "    required_fields = ['audio_filename', 'canonical_composer', 'canonical_title']\n",
    "    for field in required_fields:\n",
    "        if field not in maestro_metadata:\n",
    "            raise Exception(f\"Required field '{field}' not found in metadata. Available fields: {list(maestro_metadata.keys())}\")\n",
    "    \n",
    "    # Get the audio filenames from the pandas-style structure\n",
    "    audio_filenames = maestro_metadata['audio_filename']\n",
    "    if not isinstance(audio_filenames, dict):\n",
    "        raise Exception(f\"Expected dict for audio_filename field, got {type(audio_filenames)}\")\n",
    "    \n",
    "    total_files = len(audio_filenames)\n",
    "    print(f\"üìù Found {total_files} audio files in metadata\")\n",
    "    \n",
    "    # Get list of audio files to process\n",
    "    target_files = set()\n",
    "    files_to_process = list(audio_filenames.items())\n",
    "    if max_files:\n",
    "        files_to_process = files_to_process[:max_files]\n",
    "        print(f\"üéØ Processing first {max_files} files for demo/testing\")\n",
    "    else:\n",
    "        print(f\"üéØ Processing all {total_files} files\")\n",
    "    \n",
    "    for idx, filename in files_to_process:\n",
    "        if filename and isinstance(filename, str) and filename.endswith('.wav'):\n",
    "            target_files.add(filename)\n",
    "    \n",
    "    if not target_files:\n",
    "        raise Exception(\"No valid .wav files found in metadata\")\n",
    "    \n",
    "    print(f\"üéµ Target: {len(target_files)} audio files from ZIP\")\n",
    "    \n",
    "    # Download and stream process the MAESTRO ZIP\n",
    "    zip_url = \"https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0.zip\"\n",
    "    print(f\"üì¶ Downloading MAESTRO ZIP stream from: {zip_url}\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    \n",
    "    try:\n",
    "        # Stream download the ZIP file\n",
    "        with requests.get(zip_url, stream=True, timeout=300) as zip_response:\n",
    "            zip_response.raise_for_status()\n",
    "            \n",
    "            print(\"‚úÖ ZIP stream connected, processing...\")\n",
    "            \n",
    "            # Create a temporary file to hold the ZIP stream\n",
    "            with tempfile.NamedTemporaryFile(suffix='.zip') as temp_zip:\n",
    "                # Download ZIP in chunks to avoid memory issues\n",
    "                total_size = int(zip_response.headers.get('content-length', 0))\n",
    "                downloaded = 0\n",
    "                \n",
    "                print(f\"üìä ZIP size: {total_size / (1024**3):.1f}GB\")\n",
    "                \n",
    "                for chunk in zip_response.iter_content(chunk_size=8192 * 1024):  # 8MB chunks\n",
    "                    if chunk:\n",
    "                        temp_zip.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        \n",
    "                        # Show progress every 1GB\n",
    "                        if downloaded % (1024**3) < (8192 * 1024):\n",
    "                            progress = (downloaded / total_size) * 100 if total_size > 0 else 0\n",
    "                            print(f\"üì• Downloaded: {downloaded / (1024**3):.1f}GB ({progress:.1f}%)\")\n",
    "                \n",
    "                print(\"‚úÖ ZIP download completed, extracting audio files...\")\n",
    "                temp_zip.seek(0)  # Reset file pointer\n",
    "                \n",
    "                # Process ZIP contents\n",
    "                with zipfile.ZipFile(temp_zip, 'r') as zip_file:\n",
    "                    # Get list of files in ZIP\n",
    "                    zip_files = zip_file.namelist()\n",
    "                    audio_files_in_zip = [f for f in zip_files if f.endswith('.wav')]\n",
    "                    \n",
    "                    print(f\"üìÇ Found {len(audio_files_in_zip)} audio files in ZIP\")\n",
    "                    \n",
    "                    # Process target files found in ZIP\n",
    "                    for zip_audio_path in audio_files_in_zip:\n",
    "                        # Check if this file is in our target list\n",
    "                        audio_filename = Path(zip_audio_path).name\n",
    "                        if not any(audio_filename in target_file for target_file in target_files):\n",
    "                            continue\n",
    "                            \n",
    "                        try:\n",
    "                            print(f\"üéõÔ∏è Processing: {audio_filename}...\")\n",
    "                            \n",
    "                            # Extract audio file to memory\n",
    "                            with zip_file.open(zip_audio_path) as audio_file:\n",
    "                                audio_data = audio_file.read()\n",
    "                            \n",
    "                            # Save to temp file for librosa\n",
    "                            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:\n",
    "                                temp_audio.write(audio_data)\n",
    "                                temp_audio_path = temp_audio.name\n",
    "                            \n",
    "                            try:\n",
    "                                # Load audio (limit duration to save memory)\n",
    "                                y, sr = librosa.load(temp_audio_path, sr=22050, duration=60.0)  # 60 seconds\n",
    "                                \n",
    "                                # Generate mel-spectrogram\n",
    "                                mel_spec = librosa.feature.melspectrogram(\n",
    "                                    y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128\n",
    "                                )\n",
    "                                mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "                                \n",
    "                                # Save spectrogram to Drive\n",
    "                                spec_filename = Path(audio_filename).stem + '_mel.npy'\n",
    "                                spec_path = f'/content/drive/MyDrive/piano_transformer/processed_spectrograms/{spec_filename}'\n",
    "                                \n",
    "                                np.save(spec_path, mel_spec_db)\n",
    "                                print(f\"‚úÖ Saved: {spec_filename} (shape: {mel_spec_db.shape})\")\n",
    "                                processed_count += 1\n",
    "                                \n",
    "                                # Check if we've reached our target (if max_files is set)\n",
    "                                if max_files and processed_count >= max_files:\n",
    "                                    print(f\"üéØ Reached target limit of {processed_count} files\")\n",
    "                                    break\n",
    "                                    \n",
    "                            except Exception as audio_error:\n",
    "                                print(f\"‚ùå Audio processing error: {audio_error}\")\n",
    "                                continue\n",
    "                            finally:\n",
    "                                # Cleanup temp audio file\n",
    "                                if os.path.exists(temp_audio_path):\n",
    "                                    os.remove(temp_audio_path)\n",
    "                                    \n",
    "                        except Exception as extract_error:\n",
    "                            print(f\"‚ùå Extraction error for {zip_audio_path}: {extract_error}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Storage check periodically\n",
    "                        if processed_count % 10 == 0:\n",
    "                            try:\n",
    "                                storage_info = os.statvfs('/content')\n",
    "                                free_gb = (storage_info.f_bavail * storage_info.f_frsize) / (1024**3)\n",
    "                                print(f\"üíæ Storage: {free_gb:.1f}GB free, {processed_count} files processed\")\n",
    "                            except OSError:\n",
    "                                pass\n",
    "                        \n",
    "                        # Break if we've reached our target\n",
    "                        if max_files and processed_count >= max_files:\n",
    "                            break\n",
    "    \n",
    "    except requests.exceptions.RequestException as download_error:\n",
    "        raise Exception(f\"Failed to download MAESTRO ZIP: {download_error}\")\n",
    "    except zipfile.BadZipFile as zip_error:\n",
    "        raise Exception(f\"Invalid ZIP file: {zip_error}\")\n",
    "    except Exception as general_error:\n",
    "        raise Exception(f\"Processing error: {general_error}\")\n",
    "    \n",
    "    print(f\"\\nüéâ Streaming processing completed!\")\n",
    "    print(f\"‚úÖ Successfully processed: {processed_count} files\")\n",
    "    print(f\"üíæ Spectrograms saved to: /content/drive/MyDrive/piano_transformer/processed_spectrograms/\")\n",
    "    \n",
    "    if processed_count == 0:\n",
    "        raise Exception(\"No files were successfully processed\")\n",
    "    \n",
    "    return processed_count\n",
    "\n",
    "\n",
    "# Run streaming processing with proper error handling\n",
    "try:\n",
    "    # Set max_files=None to process all files, or set a number for testing\n",
    "    # For testing: max_files=50\n",
    "    # For full dataset: max_files=None\n",
    "    num_processed = download_and_process_maestro_streaming(max_files=None)\n",
    "    print(f\"\\n‚úÖ SUCCESS: {num_processed} MAESTRO files processed!\")\n",
    "    print(\"üéØ Ready to proceed with pre-training on processed spectrograms\")\n",
    "        \n",
    "except Exception as main_error:\n",
    "    print(f\"‚ùå Processing failed: {main_error}\")\n",
    "    raise Exception(f\"MAESTRO processing failed: {main_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Quick TPU Verification\n",
    "import jax\n",
    "\n",
    "print(\"üß† Quick TPU check...\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"Device count: {jax.device_count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssast_pretraining"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Dataset Setup from Processed Spectrograms\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "print(\"üéµ Setting up dataset from processed spectrograms...\")\n",
    "\n",
    "# Check processed spectrograms\n",
    "spec_dir = '/content/drive/MyDrive/piano_transformer/processed_spectrograms'\n",
    "if not os.path.exists(spec_dir):\n",
    "    raise FileNotFoundError(\"Run Cell 3 first to process MAESTRO\")\n",
    "\n",
    "spec_files = [f for f in os.listdir(spec_dir) if f.endswith('_mel.npy')]\n",
    "if len(spec_files) == 0:\n",
    "    raise FileNotFoundError(\"No spectrograms found. Re-run Cell 3\")\n",
    "\n",
    "print(f\"üìä Found {len(spec_files)} processed spectrograms\")\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = '/content/drive/MyDrive/piano_transformer/maestro_metadata.json'\n",
    "with open(metadata_path, 'r') as f:\n",
    "    maestro_metadata = json.load(f)\n",
    "print(\"‚úÖ MAESTRO metadata loaded\")\n",
    "\n",
    "# Dataset class for pre-processed spectrograms\n",
    "class ProcessedSpectrogramDataset:\n",
    "    def __init__(self, spec_dir, metadata):\n",
    "        self.spec_dir = spec_dir\n",
    "        self.metadata = metadata\n",
    "        self.spec_files = [f for f in os.listdir(spec_dir) if f.endswith('_mel.npy')]\n",
    "        self.num_files = len(self.spec_files)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_files\n",
    "    \n",
    "    def load_spectrogram(self, idx):\n",
    "        spec_file = self.spec_files[idx]\n",
    "        spec_path = os.path.join(self.spec_dir, spec_file)\n",
    "        return np.load(spec_path)\n",
    "    \n",
    "    def get_batch(self, batch_size=32):\n",
    "        batch_indices = np.random.choice(self.num_files, batch_size, replace=True)\n",
    "        batch_specs = []\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            spec = self.load_spectrogram(idx)\n",
    "            # Normalize to 128x128\n",
    "            if spec.shape[1] >= 128:\n",
    "                spec = spec[:, :128]\n",
    "            else:\n",
    "                pad_width = 128 - spec.shape[1]\n",
    "                spec = np.pad(spec, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            \n",
    "            batch_specs.append(spec)\n",
    "        \n",
    "        return np.array(batch_specs)\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = ProcessedSpectrogramDataset(spec_dir, maestro_metadata)\n",
    "print(f\"‚úÖ Dataset ready: {len(dataset)} spectrograms\")\n",
    "\n",
    "# Test batch loading\n",
    "test_batch = dataset.get_batch(4)\n",
    "print(f\"‚úÖ Test batch: shape {test_batch.shape}\")\n",
    "print(\"üéØ Ready for SSAST pre-training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "switch_gpu_instructions"
   },
   "outputs": [],
   "source": [
    "# Cell 6: SSAST Pre-training (Production - Full MAESTRO Dataset)\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "if 'dataset' not in locals():\n",
    "    raise RuntimeError(\"Run Cell 5 first to load dataset\")\n",
    "\n",
    "print(\"üß† Starting SSAST pre-training (PRODUCTION MODE)...\")\n",
    "print(f\"üìä Training on {len(dataset)} MAESTRO spectrograms\")\n",
    "\n",
    "# Import SSAST components\n",
    "try:\n",
    "    from models.ssast_pretraining import (\n",
    "        SSASTPreTrainingModel,\n",
    "        create_ssast_train_state,\n",
    "        ssast_train_step\n",
    "    )\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    print(\"‚úÖ SSAST components imported successfully\")\n",
    "\n",
    "    # Initialize model for production\n",
    "    model = SSASTPreTrainingModel(\n",
    "        embed_dim=768,\n",
    "        num_layers=12,\n",
    "        num_heads=12,\n",
    "        patch_size=16,\n",
    "        mask_prob=0.15\n",
    "    )\n",
    "\n",
    "    # Create training state with proper learning rate schedule\n",
    "    rng = jax.random.PRNGKey(42)\n",
    "    sample_batch = dataset.get_batch(8)  # Sample for initialization\n",
    "    input_shape = sample_batch.shape  # (batch, freq, time)\n",
    "\n",
    "    train_state = create_ssast_train_state(\n",
    "        model,\n",
    "        rng,\n",
    "        input_shape,\n",
    "        learning_rate=1e-4  # Will use cosine decay schedule internally\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Model initialized: {input_shape} -> SSAST\")\n",
    "    print(f\"üìä Total parameters: {sum(x.size for x in jax.tree.leaves(train_state.params)):,}\")\n",
    "\n",
    "    # Production training parameters\n",
    "    num_epochs = 100\n",
    "    batch_size = 32  # Adjust based on TPU memory\n",
    "    batches_per_epoch = max(len(dataset) // batch_size, 10)  # At least 10 batches per epoch\n",
    "    save_every = 10\n",
    "    log_every = 5  # Log progress every 5 batches\n",
    "\n",
    "    print(f\"üéØ Training config:\")\n",
    "    print(f\"   ‚Ä¢ Epochs: {num_epochs}\")\n",
    "    print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
    "    print(f\"   ‚Ä¢ Batches per epoch: {batches_per_epoch}\")\n",
    "    print(f\"   ‚Ä¢ Total training steps: {num_epochs * batches_per_epoch:,}\")\n",
    "\n",
    "    checkpoint_dir = '/content/drive/MyDrive/piano_transformer/checkpoints/ssast'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    training_losses = []\n",
    "    step_losses = []\n",
    "\n",
    "    print(f\"\\nüöÄ Starting production SSAST pre-training...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_losses = []\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "            # Get batch and convert to JAX array\n",
    "            batch = dataset.get_batch(batch_size)\n",
    "            batch_jax = jnp.array(batch.transpose(0, 2, 1))  # (batch, time, freq)\n",
    "\n",
    "            # Training step\n",
    "            rng, step_rng = jax.random.split(rng)\n",
    "            train_state, metrics = ssast_train_step(train_state, batch_jax, step_rng)\n",
    "\n",
    "            current_loss = float(metrics['total_loss'])\n",
    "            epoch_losses.append(current_loss)\n",
    "            step_losses.append(current_loss)\n",
    "\n",
    "            # Log progress\n",
    "            if (batch_idx + 1) % log_every == 0 or batch_idx == 0:\n",
    "                disc_loss = float(metrics.get('discriminative_loss', 0))\n",
    "                gen_loss = float(metrics.get('generative_loss', 0))\n",
    "\n",
    "                print(f\"  Batch {batch_idx+1}/{batches_per_epoch}: \"\n",
    "                      f\"Total={current_loss:.4f}, Disc={disc_loss:.4f}, Gen={gen_loss:.4f}\")\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        training_losses.append(avg_loss)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        print(f\"\\nüìä Epoch {epoch+1} Summary:\")\n",
    "        print(f\"   ‚Ä¢ Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Best Loss: {min(best_loss, avg_loss):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Epoch Time: {epoch_time/60:.1f}m\")\n",
    "        print(f\"   ‚Ä¢ Total Time: {elapsed_time/3600:.1f}h\")\n",
    "        print(f\"   ‚Ä¢ Step: {train_state.step}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        should_save = (avg_loss < best_loss) or ((epoch + 1) % save_every == 0) or (epoch == num_epochs - 1)\n",
    "\n",
    "        if should_save:\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, 'best_model_params.pkl')\n",
    "                print(f\"üèÜ New best model! Saving...\")\n",
    "            else:\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}_params.pkl')\n",
    "                print(f\"üíæ Saving checkpoint...\")\n",
    "\n",
    "            # Save checkpoint with comprehensive info\n",
    "            checkpoint_data = {\n",
    "                'params': train_state.params,\n",
    "                'step': train_state.step,\n",
    "                'epoch': epoch + 1,\n",
    "                'loss': avg_loss,\n",
    "                'best_loss': best_loss,\n",
    "                'training_time': elapsed_time,\n",
    "                'model_config': {\n",
    "                    'embed_dim': 768,\n",
    "                    'num_layers': 12,\n",
    "                    'num_heads': 12,\n",
    "                    'patch_size': 16,\n",
    "                    'mask_prob': 0.15\n",
    "                }\n",
    "            }\n",
    "\n",
    "            import pickle\n",
    "            with open(checkpoint_path, 'wb') as f:\n",
    "                pickle.dump(checkpoint_data, f)\n",
    "\n",
    "            # Save training progress\n",
    "            progress_data = {\n",
    "                'epoch': epoch + 1,\n",
    "                'training_losses': training_losses,\n",
    "                'step_losses': step_losses[-100:],  # Last 100 steps\n",
    "                'best_loss': best_loss,\n",
    "                'elapsed_time': elapsed_time\n",
    "            }\n",
    "\n",
    "            progress_path = os.path.join(checkpoint_dir, 'training_progress.json')\n",
    "            import json\n",
    "            with open(progress_path, 'w') as f:\n",
    "                json.dump({k: v if not isinstance(v, np.ndarray) else v.tolist()\n",
    "                          for k, v in progress_data.items()}, f, indent=2)\n",
    "\n",
    "    # Final results\n",
    "    total_time = time.time() - start_time\n",
    "    results = {\n",
    "        'final_loss': training_losses[-1],\n",
    "        'best_loss': best_loss,\n",
    "        'epochs': num_epochs,\n",
    "        'total_steps': train_state.step,\n",
    "        'training_time_hours': total_time / 3600,\n",
    "        'losses': training_losses\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ SSAST PRE-TRAINING COMPLETED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìà Final Loss: {results['final_loss']:.4f}\")\n",
    "    print(f\"üèÜ Best Loss: {results['best_loss']:.4f}\")\n",
    "    print(f\"‚è±Ô∏è  Total Time: {total_time/3600:.1f} hours\")\n",
    "    print(f\"üîÑ Total Steps: {train_state.step:,}\")\n",
    "    print(f\"üìä Epochs: {num_epochs}\")\n",
    "\n",
    "    # Save comprehensive final checkpoint\n",
    "    final_checkpoint = {\n",
    "        'params': train_state.params,\n",
    "        'model_config': {\n",
    "            'embed_dim': 768,\n",
    "            'num_layers': 12,\n",
    "            'num_heads': 12,\n",
    "            'patch_size': 16,\n",
    "            'mask_prob': 0.15\n",
    "        },\n",
    "        'training_info': results,\n",
    "        'dataset_info': {\n",
    "            'num_spectrograms': len(dataset),\n",
    "            'total_training_steps': train_state.step,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "    }\n",
    "\n",
    "    final_path = os.path.join(checkpoint_dir, 'final_model_params.pkl')\n",
    "    with open(final_path, 'wb') as f:\n",
    "        pickle.dump(final_checkpoint, f)\n",
    "\n",
    "    print(f\"üíæ Final model saved: {final_path}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"SSAST model not found: {e}. Check src/models/ssast_pretraining.py exists\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed at epoch {epoch+1 if 'epoch' in locals() else 0}\")\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "    # Save emergency checkpoint if training was interrupted\n",
    "    if 'train_state' in locals():\n",
    "        emergency_path = os.path.join(checkpoint_dir, 'emergency_checkpoint.pkl')\n",
    "        emergency_data = {\n",
    "            'params': train_state.params,\n",
    "            'step': train_state.step,\n",
    "            'epoch': epoch + 1 if 'epoch' in locals() else 0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "        with open(emergency_path, 'wb') as f:\n",
    "            pickle.dump(emergency_data, f)\n",
    "        print(f\"üíæ Emergency checkpoint saved: {emergency_path}\")\n",
    "\n",
    "    raise RuntimeError(f\"Pre-training failed: {e}\")\n",
    "\n",
    "# Save final training summary\n",
    "  import json\n",
    "  from datetime import datetime\n",
    "\n",
    "  # Convert any numpy/JAX arrays to regular Python lists\n",
    "  def make_json_safe(obj):\n",
    "      if hasattr(obj, 'tolist'):  # numpy/JAX arrays\n",
    "          return obj.tolist()\n",
    "      elif isinstance(obj, list):\n",
    "          return [make_json_safe(item) for item in obj]\n",
    "      elif isinstance(obj, dict):\n",
    "          return {key: make_json_safe(value) for key, value in obj.items()}\n",
    "      else:\n",
    "          return obj\n",
    "\n",
    "  training_summary = {\n",
    "      'model': 'SSAST',\n",
    "      'dataset_size': len(dataset),\n",
    "      'final_loss': float(results['final_loss']),  # Ensure it's a Python float\n",
    "      'best_loss': float(results['best_loss']),\n",
    "      'epochs': results['epochs'],\n",
    "      'training_time_hours': float(results['training_time_hours']),\n",
    "      'total_steps': int(results['total_steps']),  # Ensure it's a Python int\n",
    "      'timestamp': datetime.now().isoformat(),\n",
    "      'production_mode': True\n",
    "      # Note: Removed 'losses' array to avoid JSON serialization issues\n",
    "  }\n",
    "\n",
    "  training_summary = make_json_safe(training_summary)\n",
    "\n",
    "  with open('/content/drive/MyDrive/piano_transformer/pretraining_results.json', 'w') as f:\n",
    "      json.dump(training_summary, f, indent=2)\n",
    "\n",
    "  print(\"üíæ Training summary saved to Google Drive!\")\n",
    "  print(\"üéØ Ready for fine-tuning phase!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: AST Fine-tuning on PercePiano\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "try:\n",
    "    from train_ast import train_ast\n",
    "    from datasets.percepiano_dataset import PercepianoDataset\n",
    "    print(\"‚úÖ Fine-tuning modules imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Check if src/train_ast.py and src/datasets/percepiano_dataset.py exist\")\n",
    "    exit()\n",
    "\n",
    "print(\"üéπ Starting AST fine-tuning on PercePiano dataset...\")\n",
    "print(\"‚è±Ô∏è  Expected duration: ~3 hours on GPU\")\n",
    "\n",
    "# Check for pre-trained model\n",
    "pretrained_path = '/content/drive/MyDrive/piano_transformer/checkpoints/ssast/best_model.pkl'\n",
    "\n",
    "if os.path.exists(pretrained_path):\n",
    "    print(f\"‚úÖ Pre-trained model found: {pretrained_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Pre-trained model not found at: {pretrained_path}\")\n",
    "    print(\"Available checkpoints:\")\n",
    "    !ls -la /content/drive/MyDrive/piano_transformer/checkpoints/ssast/\n",
    "    # Use the latest checkpoint\n",
    "    checkpoints = !ls /content/drive/MyDrive/piano_transformer/checkpoints/ssast/*.pkl\n",
    "    if checkpoints:\n",
    "        pretrained_path = checkpoints[-1]  # Use latest\n",
    "        print(f\"Using latest checkpoint: {pretrained_path}\")\n",
    "    else:\n",
    "        print(\"No checkpoints found. Running without pre-training.\")\n",
    "        pretrained_path = None\n",
    "\n",
    "# Check PercePiano dataset\n",
    "percepiano_path = './PercePiano'\n",
    "if os.path.exists(percepiano_path):\n",
    "    print(f\"‚úÖ PercePiano dataset found: {percepiano_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå PercePiano dataset not found at: {percepiano_path}\")\n",
    "    exit()\n",
    "\n",
    "# Start fine-tuning\n",
    "print(\"üöÄ Starting fine-tuning...\")\n",
    "results = train_ast(\n",
    "    pretrained_model_path=pretrained_path,\n",
    "    percepiano_path=percepiano_path,\n",
    "    target_correlation=0.7,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-5,  # Lower LR for fine-tuning\n",
    "    checkpoint_dir='/content/drive/MyDrive/piano_transformer/checkpoints/ast_finetuned',\n",
    "    save_every=5\n",
    ")\n",
    "\n",
    "print(\"üéâ Fine-tuning completed! ‚úÖ\")\n",
    "print(f\"Best correlation achieved: {results.get('best_correlation', 'N/A'):.3f}\")\n",
    "\n",
    "# Save fine-tuning results\n",
    "with open('/content/drive/MyDrive/piano_transformer/finetuning_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "    \n",
    "print(\"üíæ Fine-tuning results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_gpu"
   },
   "outputs": [],
   "source": [
    "# Cell 9: Final Results and Evaluation\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìä Generating final results summary...\")\n",
    "\n",
    "# Load training results\n",
    "pretraining_results = {}\n",
    "finetuning_results = {}\n",
    "\n",
    "# Load pre-training results if available\n",
    "pretraining_path = '/content/drive/MyDrive/piano_transformer/pretraining_results.json'\n",
    "if os.path.exists(pretraining_path):\n",
    "    with open(pretraining_path, 'r') as f:\n",
    "        pretraining_results = json.load(f)\n",
    "    print(\"‚úÖ Pre-training results loaded\")\n",
    "\n",
    "# Load fine-tuning results if available\n",
    "finetuning_path = '/content/drive/MyDrive/piano_transformer/finetuning_results.json'\n",
    "if os.path.exists(finetuning_path):\n",
    "    with open(finetuning_path, 'r') as f:\n",
    "        finetuning_results = json.load(f)\n",
    "    print(\"‚úÖ Fine-tuning results loaded\")\n",
    "\n",
    "# Check final model\n",
    "final_model_path = '/content/drive/MyDrive/piano_transformer/checkpoints/ast_finetuned/best_model.pkl'\n",
    "model_exists = os.path.exists(final_model_path)\n",
    "\n",
    "# Generate comprehensive summary\n",
    "final_summary = {\n",
    "    'experiment_date': datetime.now().isoformat(),\n",
    "    'pipeline': {\n",
    "        'step_1': 'SSAST Pre-training on MAESTRO-v3',\n",
    "        'step_2': 'AST Fine-tuning on PercePiano'\n",
    "    },\n",
    "    'datasets': {\n",
    "        'pretraining': 'MAESTRO-v3 (200+ hours piano audio)',\n",
    "        'finetuning': 'PercePiano (1202 performances, 19 dimensions)'\n",
    "    },\n",
    "    'model_architecture': {\n",
    "        'base': 'Audio Spectrogram Transformer (AST)',\n",
    "        'pretraining': 'Self-Supervised AST (SSAST) with MSPM',\n",
    "        'parameters': '~85M (encoder) + task heads'\n",
    "    },\n",
    "    'results': {\n",
    "        'pretraining': pretraining_results,\n",
    "        'finetuning': finetuning_results,\n",
    "        'final_model_saved': model_exists\n",
    "    },\n",
    "    'target_achieved': finetuning_results.get('best_correlation', 0) >= 0.7\n",
    "}\n",
    "\n",
    "# Save comprehensive results\n",
    "final_results_path = '/content/drive/MyDrive/piano_transformer/FINAL_RESULTS.json'\n",
    "with open(final_results_path, 'w') as f:\n",
    "    json.dump(final_summary, f, indent=2)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ PIANO PERCEPTION TRANSFORMER - FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìÖ Experiment completed: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è  Architecture:\")\n",
    "print(\"   ‚Ä¢ Audio Spectrogram Transformer (AST) - 85M parameters\")\n",
    "print(\"   ‚Ä¢ Self-supervised pre-training with MSPM\")\n",
    "print(\"   ‚Ä¢ Multi-task regression for 19 perceptual dimensions\")\n",
    "\n",
    "print(\"\\nüìä Training Pipeline:\")\n",
    "print(\"   1. ‚úÖ SSAST pre-training on MAESTRO-v3 (TPU)\")\n",
    "print(\"   2. ‚úÖ AST fine-tuning on PercePiano (GPU)\")\n",
    "\n",
    "if finetuning_results:\n",
    "    best_corr = finetuning_results.get('best_correlation', 0)\n",
    "    target_met = \"‚úÖ\" if best_corr >= 0.7 else \"‚ùå\"\n",
    "    print(f\"\\nüéØ Performance:\")\n",
    "    print(f\"   ‚Ä¢ Best correlation: {best_corr:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Target >0.7: {target_met}\")\n",
    "\n",
    "print(f\"\\nüíæ All results saved to: {final_results_path}\")\n",
    "print(f\"üìÅ Model checkpoints in: /content/drive/MyDrive/piano_transformer/checkpoints/\")\n",
    "\n",
    "print(\"\\nüéä Training pipeline completed successfully!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show file structure\n",
    "print(\"\\nüìÅ Final file structure in Google Drive:\")\n",
    "!ls -la /content/drive/MyDrive/piano_transformer/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
