Metadata-Version: 2.4
Name: piano-analysis-model
Version: 0.1.0
Summary: CNN-based piano performance analysis using perceptual dimensions
Author-email: Your Name <your.email@example.com>
License: MIT
Requires-Python: <3.12,>=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch<2.1.0,>=1.13.0
Requires-Dist: torchvision<0.16.0,>=0.14.0
Requires-Dist: torchaudio<2.1.0,>=0.13.0
Requires-Dist: librosa>=0.10.0
Requires-Dist: soundfile>=0.12.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: scipy>=1.10.0
Requires-Dist: matplotlib>=3.7.0
Requires-Dist: seaborn>=0.12.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: tqdm>=4.65.0
Requires-Dist: jupyter>=1.0.0
Requires-Dist: ipykernel>=6.25.0
Requires-Dist: ipywidgets>=8.0.0
Provides-Extra: dev
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Dynamic: license-file

# My Piano Performance Analysis

**Personal recreation of PercePiano dataset analysis for deep learning fundamentals**

## Project Goal
Build piano performance analysis system from scratch to predict 19 perceptual dimensions:
- Timing, Articulation, Pedal, Timbre, Dynamics, Musical Expression, Emotion, Interpretation

## Approach 
**Phase 1**: Dataset Recreation & ML Fundamentals (Current)
- âœ… Dataset exploration and correlation analysis
- âœ… Audio preprocessing pipeline 
- ðŸš§ Feature extraction matching research approaches
- ðŸŽ¯ Single-dimension prediction model (next)

**Future Phases**: CNN architecture â†’ Multi-task learning â†’ Chopin/Liszt extension

## Repository Structure
```
my_implementation/
â”œâ”€â”€ src/           # Clean implementation code
â”œâ”€â”€ data/          # PercePiano labels and sample audio
â”œâ”€â”€ notebooks/     # Jupyter experiments 
â”œâ”€â”€ models/        # Trained model files
â”œâ”€â”€ experiments/   # Training configurations
â””â”€â”€ results/       # Analysis outputs
```

## Key Insights from Dataset Analysis
- **1202 performances** across 19 perceptual dimensions
- **22 performers**, multi-composer dataset (Schubert, Beethoven)  
- **Rating range**: [0.143, 0.976], mean=0.553
- **Strong correlations**: Related dimensions (pedal types, musical expression)
- **Audio features**: Tempoâ†’timing, spectral centroidâ†’brightness, RMSâ†’dynamics

## Next Steps
1. Build single-dimension prediction model (starting with "Timing_Stable_Unstable")
2. Implement multi-task learning for all 19 dimensions
3. Compare CNN vs traditional ML approaches
4. Extend to new repertoire (Chopin/Liszt recordings)

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Citation

If you use this software in your research, please cite it using the information in [CITATION.cff](CITATION.cff):

```bibtex
@software{piano_analysis_model,
  title = {Piano Performance Analysis Model},
  author = {Piano Analysis User},
  year = {2025},
  url = {https://github.com/username/piano-analysis-model}
}
```

## Dataset Attribution

This project uses and extends the **PercePiano dataset** for piano performance analysis:

- **Original Dataset**: Cancino-ChacÃ³n, C. E., Grachten, M., & Widmer, G. (2017). PercePiano: A Dataset for Piano Performance Analysis. *Proceedings of the International Society for Music Information Retrieval Conference*, 55-62.
- **Dataset License**: Creative Commons Attribution 4.0 International (CC BY 4.0)
- **Audio Source**: Classical piano performances from various composers
- **Labels**: Perceptual annotations across 19 dimensions

## Data Use and Redistribution

- **Code**: Available under MIT License - free to use, modify, and distribute
- **PercePiano Dataset**: Used under CC BY 4.0 - attribution required for any use
- **Audio Files**: Sample audio included for demonstration purposes only
- **Redistribution**: Full dataset redistribution must comply with original CC BY 4.0 terms

For questions about dataset usage or to access the complete PercePiano dataset, contact the original authors through the [ISMIR 2017 publication](https://doi.org/10.5334/tismir.17).

---
*Learning-focused implementation - building everything from scratch for deep understanding*
