# Google Colab Training Guide

## ğŸš€ Quick Start for Colab

### 1. Setup Environment

```python
# Run this first in Colab
!git clone https://github.com/your-username/piano-perception-transformer.git
%cd piano-perception-transformer

# Setup environment
exec(open('colab_setup.py').read())
```

### 2. Run Training

```python
# Start complete training pipeline
exec(open('colab_training.py').read())
```

## ğŸ“‹ What This Does

### Pre-training Phase (SSAST)
- **Model**: Self-Supervised Audio Spectrogram Transformer
- **Task**: Masked patch reconstruction 
- **Data**: Mel-spectrograms (128Ã—128)
- **Duration**: ~3 epochs (5-10 minutes on T4 GPU)

### Fine-tuning Phase (AST)  
- **Model**: Audio Spectrogram Transformer
- **Task**: 19-dimensional perceptual prediction
- **Transfer**: Pre-trained encoder weights
- **Duration**: ~5 epochs (5-10 minutes on T4 GPU)

## ğŸ¯ Expected Results

**Pre-training Loss**: Should decrease from ~500,000 to ~50,000
**Fine-tuning Loss**: Should decrease from ~0.5 to ~0.1

## ğŸ“ Output Files

```
checkpoints/
â”œâ”€â”€ ssast_best.pkl      # Best pre-training checkpoint
â””â”€â”€ ast_best.pkl        # Best fine-tuning checkpoint

results/
â””â”€â”€ training_results.json  # Complete training metrics
```

## ğŸ”§ Architecture Details

### AST Model
- **Patch Size**: 16Ã—16 pixels
- **Embedding**: 768 dimensions  
- **Layers**: 6 transformer blocks (Colab-optimized)
- **Heads**: 12 attention heads
- **Parameters**: ~4.5M

### SSAST Model  
- **Same architecture** as AST
- **Additional**: MSMP (Masked Spectrogram Modeling) head
- **Masking**: 75% of patches randomly masked

## ğŸµ Perceptual Dimensions

The model predicts 19 perceptual dimensions:

**Timing & Articulation**
- Timing: Stable â†” Unstable  
- Articulation: Short â†” Long
- Articulation: Soft/cushioned â†” Hard/solid

**Pedal & Timbre**
- Pedal: Sparse/dry â†” Saturated/wet
- Pedal: Clean â†” Blurred
- Timbre: Even â†” Colorful
- Timbre: Shallow â†” Rich
- Timbre: Bright â†” Dark
- Timbre: Soft â†” Loud

**Dynamics & Expression**
- Dynamic: Sophisticated/mellow â†” Raw/crude
- Dynamic: Little range â†” Large range
- Music Making: Fast paced â†” Slow paced
- Music Making: Flat â†” Spacious
- Music Making: Disproportioned â†” Balanced
- Music Making: Pure â†” Dramatic/expressive

**Emotion & Interpretation**
- Emotion: Optimistic/pleasant â†” Dark
- Emotion: Low Energy â†” High Energy  
- Emotion: Honest â†” Imaginative
- Interpretation: Unsatisfactory/doubtful â†” Convincing

## ğŸ’¡ Tips for Colab

1. **Use GPU Runtime**: Runtime â†’ Change runtime type â†’ GPU
2. **Monitor Memory**: Watch the RAM/Disk usage indicators  
3. **Save Checkpoints**: Download important checkpoints to Drive
4. **Reduce Batch Size**: If OOM, decrease batch_size in config

## ğŸ” Troubleshooting

**Out of Memory**: Reduce `embed_dim` or `num_layers`
**Slow Training**: Check GPU is enabled
**Import Errors**: Re-run `colab_setup.py`

## ğŸ“Š Monitoring Training

```python
# Plot training curves
import matplotlib.pyplot as plt
import json

with open('results/training_results.json') as f:
    results = json.load(f)

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(results['pretraining_losses'])
plt.title('Pre-training Loss')
plt.ylabel('SSAST Loss')
plt.xlabel('Epoch')

plt.subplot(1, 2, 2) 
plt.plot(results['finetuning_losses'])
plt.title('Fine-tuning Loss')
plt.ylabel('MSE Loss')
plt.xlabel('Epoch')

plt.show()
```

---

ğŸ¼ **Happy Training!** This implementation provides a solid foundation for piano performance analysis with modern transformer architectures.